{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9d8e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys; sys.path.append(\"../\")\n",
    "import tiktoken\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "\n",
    "from model import GPTConfig, GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cde2b6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.memmap('../data/openwebtext/train.bin', dtype=np.uint16, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "999db5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9035582489,)\n",
      "9035582489\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d47cf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8585\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39aa2d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "def process(example):\n",
    "    ids = enc.encode_ordinary(example['text']) # encode_ordinary ignores any special tokens\n",
    "    ids.append(enc.eot_token) # add the end of text token, e.g. 50256 for gpt2 bpe\n",
    "    # note: I think eot should be prepended not appended... hmm. it's called \"eot\" though...\n",
    "    out = {'ids': ids, 'len': len(ids)}\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3ad5576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [15496, 995, 50256], 'len': 3}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process({'text':\"Hello world\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b60ae764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: gpt2\n",
      "forcing vocab_size=50257, block_size=1024, bias=True\n",
      "number of parameters: 123.65M\n"
     ]
    }
   ],
   "source": [
    "model = GPT.from_pretrained(\"gpt2\", {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6900b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wte = None\n",
    "for name, param in model.named_parameters():\n",
    "    if name == 'transformer.wte.weight':\n",
    "        wte = param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73cbe03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wte_embed = nn.Embedding(50257, 768)\n",
    "wte_embed.weight = wte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eca3044f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 768])\n"
     ]
    }
   ],
   "source": [
    "print(wte_embed(torch.tensor([15496, 995, 50256])).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c7e97e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wte_OWT = wte_embed(torch.from_numpy((train_data[:1000]).astype(np.int64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73503b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 768])\n"
     ]
    }
   ],
   "source": [
    "print(wte_OWT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "240b5075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 105.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0004901625216007233\n",
      "0.11476480462755997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Find mean of embedding\n",
    "batch_size = 10000\n",
    "batches = math.floor(9035582489/batch_size)\n",
    "m, m_sq = 0, 0\n",
    "for i in tqdm(range(10)):\n",
    "    wte_OWT = wte_embed(torch.from_numpy((train_data[i*batch_size:(i+1)*batch_size]).astype(np.int64)))\n",
    "    m = ((i*m) + torch.mean(wte_OWT))/(i+1)\n",
    "    m_sq = ((i*m_sq) + torch.mean(wte_OWT**2))/(i+1)\n",
    "#     m += 1\n",
    "# wte_OWT = wte_embed(torch.from_numpy((train_data[i*batch_size:]).astype(np.int64)))\n",
    "# m = ((batch_size*i*m) + torch.sum(wte_OWT))/len(train_data)\n",
    "print(m.item())\n",
    "print(np.sqrt(m_sq.item() - m.item()**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2898f9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 134.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11476480215787888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Find std of embedding\n",
    "std = 0\n",
    "for i in tqdm(range(10)):\n",
    "    wte_OWT = wte_embed(torch.from_numpy((train_data[i*batch_size:(i+1)*batch_size]).astype(np.int64)))\n",
    "    std = ((i*std) + torch.mean((wte_OWT-m)**2))/(i+1)\n",
    "#     m += 1\n",
    "# wte_OWT = wte_embed(torch.from_numpy((train_data[i*batch_size:]).astype(np.int64)))\n",
    "# m = ((batch_size*i*m) + torch.sum(wte_OWT))/len(train_data)\n",
    "print(torch.sqrt(std).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5eb467e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11476480215787888"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std(wte_embed(torch.from_numpy((train_data[:batch_size*10]).astype(np.int64)))).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "faf1e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1308\n",
    "wte_OWT = wte_embed(torch.from_numpy((train_data[i*batch_size:(i+1)*batch_size]).astype(np.int64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bd2717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
